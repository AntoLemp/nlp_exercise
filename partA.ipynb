{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c820456c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing: thank you for your message, which helped convey our thoughts to the doctor, who will assist all of us with checking the next contract .\n",
      "Tokens: ['thank', 'you', 'for', 'your', 'message', 'which', 'helped', 'convey', 'our', 'thoughts', 'to', 'the', 'doctor', 'who', 'will', 'assist', 'all', 'of', 'us', 'with', 'checking', 'the', 'next', 'contract']\n",
      "\n",
      "\n",
      "Parsing: anyway, i believe the team really did their best with the paper, even though there were some delays and less communication lately. \n",
      "Tokens: ['anyway', 'i', 'believe', 'the', 'team', 'really', 'did', 'their', 'best', 'with', 'the', 'paper', 'even', 'though', 'there', 'were', 'some', 'delays', 'and', 'less', 'communication', 'lately']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "sentences = [\n",
    "    \"Thank your message to show our words to the doctor, as his next contract checking, to all of us\",\n",
    "    \"Anyway, I believe the team, although bit delay and less communication at recent days, they really tried best for paper and cooperation\",\n",
    "]\n",
    "# simple context free grammar\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP | VP | Adv S | S Conj S | VP VP\n",
    "    NP -> Det N | Det N PP | Det Adj N | Det Adj N PP | NP PP | Pronoun | NP Conj NP | Adj N | N \n",
    "    PP -> P NP\n",
    "    VP -> V NP | VP PP | V | Adv VP | VP Adv | V Pronoun\n",
    "    Det -> 'the' | 'a' | 'your' | 'our' | 'his' | 'all' | 'which' | 'some' | 'their'\n",
    "    Adj -> 'next' | 'recent' | 'bit' | 'less' | 'best' \n",
    "    Adv -> 'anyway' | 'really'  | 'even' | 'lately' | 'there'\n",
    "    Pronoun -> 'us' | 'they' | 'i' | 'you' | 'he' | 'she' | 'who'\n",
    "    N -> 'doctor' | 'team' | 'message' | 'words' | 'contract' | 'days' | 'paper' | 'cooperation' | 'delay' | 'communication' | 'thoughts'\n",
    "    P -> 'to' | 'as' | 'for' | 'of' | 'at' | 'with' | 'in' | 'on' | 'by'\n",
    "    V -> 'show' | 'believe' | 'tried' | 'thank' | 'helped' | 'assist' | 'convey' | 'will' | 'checking' | 'were' | 'delays' | 'did'\n",
    "    Conj -> 'and' | 'though' | 'although'\n",
    "\"\"\")\n",
    "stop_words = [ '.', ',']\n",
    "# create a parser\n",
    "parser = nltk.ChartParser(grammar)\n",
    "# parse the sentences\n",
    "# fix the sentences\n",
    "# to make them more grammatically correct\n",
    "# and to match the grammar\n",
    "def sentence_fixer(sentence):\n",
    "    replace = {\n",
    "        \"your message\": \"you for your message,\",\n",
    "        \"to show our words\": \"which helped convey our thoughts\",\n",
    "        \"as his\": \"who will assist all of us with checking the\",\n",
    "        \"checking, to all of us\": \".\",\n",
    "        \"Anyway, \": \"\",\n",
    "        \", although\": \" really did their best with the paper,\",\n",
    "        \"bit delay\": \"even though there were some delays\",\n",
    "        \"at recent days,\": \"lately.\",\n",
    "        \"they really tried best for paper and cooperation\": \"\"\n",
    "    }\n",
    "    for key, value in replace.items():\n",
    "        sentence = sentence.lower().replace(key, value)\n",
    "    return sentence\n",
    "\n",
    "sentences_fixed = [sentence_fixer(sentence) for sentence in sentences]\n",
    "\n",
    "for sentence in sentences_fixed:\n",
    "    print(f\"Parsing: {sentence}\")\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    tokens = [token.lower() for token in tokens if token not in stop_words]\n",
    "    print(f\"Tokens: {tokens}\")\n",
    "    \n",
    "    for tree in parser.parse(tokens):\n",
    "        print(tree)\n",
    "        tree.pretty_print()\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3028078a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed sentence: thank you t o show our words to the doctor , as his next contract checking , to all of us\n"
     ]
    }
   ],
   "source": [
    "def extract_n_gram(sentences, n):\n",
    "    n_grams = []\n",
    "    for sentence in sentences:\n",
    "        tokens = nltk.word_tokenize(sentence.lower())\n",
    "        n_grams.extend(list(nltk.ngrams(tokens, n)))\n",
    "    return n_grams\n",
    "\n",
    "def fix_sentence_with_ngrams(sentence, bad_to_good_map, n=2):\n",
    "    tokens = nltk.word_tokenize(sentence.lower())\n",
    "    i = 0\n",
    "    fixed_tokens = []\n",
    "\n",
    "    while i < len(tokens):\n",
    "        match_found = False\n",
    "        if i + n <= len(tokens):\n",
    "            current_ngram = tuple(tokens[i:i+n])\n",
    "            if current_ngram in bad_to_good_map:\n",
    "                # Replace with the good n-gram\n",
    "                fixed_tokens.extend(bad_to_good_map[current_ngram])\n",
    "                i += n  # Skip ahead by n tokens\n",
    "                match_found = True\n",
    "\n",
    "        if not match_found:\n",
    "            fixed_tokens.append(tokens[i])\n",
    "            i += 1\n",
    "\n",
    "    return ' '.join(fixed_tokens)\n",
    "\n",
    "# Example replacement rule\n",
    "bad_to_good = {\n",
    "    ('thank', 'your'): ('thank', 'you'),\n",
    "    ('your', 'message'): ('for', 'your', 'message'),\n",
    "    ('message', 'to'): ('to'),\n",
    "\n",
    "}\n",
    "\n",
    "fixed = fix_sentence_with_ngrams(sentences[0], bad_to_good)\n",
    "print(\"Fixed sentence:\", fixed)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "377f6326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in our lives.\n",
      "Paraphrased: Our Chinese culture celebrates today's dragon boat festival to ensure the safety and prosperity of all who come from this world.\n",
      "Paraphrased: In our Chinese culture, we celebrate today's dragon boat festival to make it a day to remember with great safety and comfort.\n",
      "Paraphrased: According to Chinese customs, today's celebration of the dragon boat is a way to honor the safety and greatness of our lives.\n",
      "\n",
      "\n",
      "Original: Hope you too, to enjoy it as my deepest wishes.\n",
      "Paraphrased: Let's all have a wonderful time together, dear friends.\n",
      "Paraphrased: May you also have a good time as my thoughts are with you.\n",
      "Paraphrased: I hope you enjoy it as much as I do.\n",
      "\n",
      "\n",
      "Original: Thank your message to show our words to the doctor, as his next contract checking, to all of us.\n",
      "Paraphrased: As the doctor conducts his next contract check, I thank you for your message on how we can communicate with him.\n",
      "Paraphrased: We appreciate your message, as we are tasked with sharing our thoughts with the doctor during his next contract check-up.\n",
      "Paraphrased: I want to thank you for your message, as we are preparing to discuss with the doctor during his next contract check.\n",
      "\n",
      "\n",
      "Original: I got this message to see the approved message.\n",
      "Paraphrased: I was notified to view the authorized message.\n",
      "Paraphrased: The message was sent to me with the intention of viewing the authorized message.\n",
      "Paraphrased: My intention is to view the authorized message after receiving this message.\n",
      "\n",
      "\n",
      "Original: In fact, I have received the message from the professor, to show me, this, a couple of days ago.\n",
      "Paraphrased: It's been two days since the professor sent me a message, so I had to show him this.\n",
      "Paraphrased: A message was sent by the professor to me, showing me this a few days ago.\n",
      "Paraphrased: The professor sent me a message to show me this, which happened just 1-2 days ago.\n",
      "\n",
      "\n",
      "Original: I am very appreciated the full support of the professor, for our Springer proceedings publication\n",
      "Paraphrased: The professor's complete backing has been appreciated for publishing our Springer proceedings.\n",
      "Paraphrased: It is truly appreciated to have the complete support of the professor in assisting us with our Springer proceedings publication.\n",
      "Paraphrased: Thanks to the professor's complete support, I am able to publish our Springer proceedings.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\").to(device)\n",
    "\n",
    "def paraphrase(\n",
    "    question,\n",
    "    num_beams=5,\n",
    "    num_beam_groups=5,\n",
    "    num_return_sequences=3,\n",
    "    repetition_penalty=10.0,\n",
    "    diversity_penalty=3.0,\n",
    "    no_repeat_ngram_size=2,\n",
    "    temperature=0.7,\n",
    "    max_length=128\n",
    "):\n",
    "    input_ids = tokenizer(\n",
    "        f'paraphrase: {question}',\n",
    "        return_tensors=\"pt\", padding=\"longest\",\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "    ).input_ids.to(device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids, temperature=temperature, repetition_penalty=repetition_penalty,\n",
    "        num_return_sequences=num_return_sequences, no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "        num_beams=num_beams, num_beam_groups=num_beam_groups,\n",
    "        max_length=max_length, diversity_penalty=diversity_penalty\n",
    "    )\n",
    "\n",
    "    res = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    return res\n",
    "\n",
    "text1 = [\"Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in our lives.\",\n",
    "\"Hope you too, to enjoy it as my deepest wishes.\",\n",
    "\"Thank your message to show our words to the doctor, as his next contract checking, to all of us.\",\n",
    "\"I got this message to see the approved message.\",\n",
    "\"In fact, I have received the message from the professor, to show me, this, a couple of days ago.\",\n",
    "\"I am very appreciated the full support of the professor, for our Springer proceedings publication\"\n",
    "]\n",
    "\n",
    "for text in text1:\n",
    "    print(f\"Original: {text}\")\n",
    "    paraphrased = paraphrase(text)\n",
    "    for p in paraphrased:\n",
    "        print(f\"Paraphrased: {p}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e22c8aa",
   "metadata": {},
   "source": [
    "chatgpt_paraphraser:\n",
    "  author={Vladimir Vorobev, Maxim Kuznetsov},\n",
    "  title={A paraphrasing model based on ChatGPT paraphrases},\n",
    "  year={2023}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
