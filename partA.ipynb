{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c820456c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing: thank you for your message,\n",
      "Tokens: ['thank', 'you', 'for', 'your', 'message']\n",
      "(S\n",
      "  (VP\n",
      "    (V thank)\n",
      "    (NP (NP (Pronoun you)) (PP (P for) (NP (Det your) (N message))))))\n",
      "               S                      \n",
      "               |                       \n",
      "               VP                     \n",
      "   ____________|___                    \n",
      "  |                NP                 \n",
      "  |       _________|___                \n",
      "  |      |             PP             \n",
      "  |      |      _______|____           \n",
      "  |      NP    |            NP        \n",
      "  |      |     |        ____|_____     \n",
      "  V   Pronoun  P      Det         N   \n",
      "  |      |     |       |          |    \n",
      "thank   you   for     your     message\n",
      "\n",
      "\n",
      "\n",
      "Parsing: it helped convey our thoughts to the doctor,\n",
      "Tokens: ['it', 'helped', 'convey', 'our', 'thoughts', 'to', 'the', 'doctor']\n",
      "(S\n",
      "  (NP (Pronoun it))\n",
      "  (VP\n",
      "    (VP (V helped) (VP (V convey) (NP (Det our) (N thoughts))))\n",
      "    (PP (P to) (NP (Det the) (N doctor)))))\n",
      "                           S                                 \n",
      "    _______________________|_________                         \n",
      "   |                                 VP                      \n",
      "   |                    _____________|__________              \n",
      "   |                   VP                       |            \n",
      "   |       ____________|___                     |             \n",
      "   |      |                VP                   PP           \n",
      "   |      |       _________|___              ___|___          \n",
      "   NP     |      |             NP           |       NP       \n",
      "   |      |      |          ___|_____       |    ___|____     \n",
      "Pronoun   V      V        Det        N      P  Det       N   \n",
      "   |      |      |         |         |      |   |        |    \n",
      "   it   helped convey     our     thoughts  to the     doctor\n",
      "\n",
      "\n",
      "\n",
      "Parsing: who will assist all of us with checking the next contract .\n",
      "Tokens: ['who', 'will', 'assist', 'all', 'of', 'us', 'with', 'checking', 'the', 'next', 'contract']\n",
      "(S\n",
      "  (NP (Pronoun who))\n",
      "  (VP\n",
      "    (VP\n",
      "      (V will)\n",
      "      (VP (V assist) (NP (Det all) (PP (P of) (NP (Pronoun us))))))\n",
      "    (PP\n",
      "      (P with)\n",
      "      (NP (N checking) (NP (Det the) (Adj next) (N contract))))))\n",
      "               S                                                               \n",
      "    ___________|_______________________                                         \n",
      "   |                                   VP                                      \n",
      "   |                  _________________|___________________                     \n",
      "   |                 VP                                    |                   \n",
      "   |      ___________|___                                  |                    \n",
      "   |     |               VP                                |                   \n",
      "   |     |      _________|___                              |                    \n",
      "   |     |     |             NP                            PP                  \n",
      "   |     |     |      _______|___             _____________|___                 \n",
      "   |     |     |     |           PP          |                 NP              \n",
      "   |     |     |     |        ___|_____      |       __________|___             \n",
      "   NP    |     |     |       |         NP    |      |              NP          \n",
      "   |     |     |     |       |         |     |      |       _______|______      \n",
      "Pronoun  V     V    Det      P      Pronoun  P      N     Det     Adj     N    \n",
      "   |     |     |     |       |         |     |      |      |       |      |     \n",
      "  who   will assist all      of        us   with checking the     next contract\n",
      "\n",
      "\n",
      "\n",
      "Parsing: i believe the team really did their best with the paper, though there were some delays and less communication lately. \n",
      "Tokens: ['i', 'believe', 'the', 'team', 'really', 'did', 'their', 'best', 'with', 'the', 'paper', 'though', 'there', 'were', 'some', 'delays', 'and', 'less', 'communication', 'lately']\n",
      "(S\n",
      "  (NP (Pronoun i))\n",
      "  (VP\n",
      "    (VP\n",
      "      (V believe)\n",
      "      (S\n",
      "        (NP (Det the) (N team))\n",
      "        (VP\n",
      "          (Adv really)\n",
      "          (VP\n",
      "            (V did)\n",
      "            (S\n",
      "              (NP\n",
      "                (NP\n",
      "                  (NP (Det their) (N best))\n",
      "                  (PP (P with) (NP (Det the) (N paper))))\n",
      "                (Conj though)\n",
      "                (NP (Pronoun there)))\n",
      "              (VP\n",
      "                (V were)\n",
      "                (NP\n",
      "                  (NP (Det some) (N delays))\n",
      "                  (Conj and)\n",
      "                  (NP (Adj less) (NP (N communication))))))))))\n",
      "    (Adv lately)))\n",
      "                                                             S                                                                                  \n",
      "    _________________________________________________________|________                                                                           \n",
      "   |                                                                  VP                                                                        \n",
      "   |              ____________________________________________________|_____________________________________________________________________     \n",
      "   |             VP                                                                                                                         |   \n",
      "   |        _____|_____________                                                                                                             |    \n",
      "   |       |                   S                                                                                                            |   \n",
      "   |       |          _________|___________________                                                                                         |    \n",
      "   |       |         |                             VP                                                                                       |   \n",
      "   |       |         |          ___________________|________________________                                                                |    \n",
      "   |       |         |         |                                            VP                                                              |   \n",
      "   |       |         |         |      ______________________________________|_______                                                        |    \n",
      "   |       |         |         |     |                                              S                                                       |   \n",
      "   |       |         |         |     |                        ______________________|____________________                                   |    \n",
      "   |       |         |         |     |                       NP                                          VP                                 |   \n",
      "   |       |         |         |     |                   ____|______________________       ______________|_____                             |    \n",
      "   |       |         |         |     |                  NP                  |       |     |                    NP                           |   \n",
      "   |       |         |         |     |          ________|____               |       |     |          __________|_________                   |    \n",
      "   |       |         |         |     |         |             PP             |       |     |         |          |         NP                 |   \n",
      "   |       |         |         |     |         |         ____|___           |       |     |         |          |     ____|________          |    \n",
      "   NP      |         NP        |     |         NP       |        NP         |       NP    |         NP         |    |             NP        |   \n",
      "   |       |      ___|___      |     |     ____|___     |     ___|____      |       |     |     ____|____      |    |             |         |    \n",
      "Pronoun    V    Det      N    Adv    V   Det       N    P   Det       N    Conj  Pronoun  V   Det        N    Conj Adj            N        Adv  \n",
      "   |       |     |       |     |     |    |        |    |    |        |     |       |     |    |         |     |    |             |         |    \n",
      "   i    believe the     team really did their     best with the     paper though  there  were some     delays and  less     communication lately\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "sentences = [\n",
    "    \"Thank your message\",\n",
    "    \"to show our words to the doctor,\",\n",
    "    \"as his next contract checking, to all of us\",\n",
    "    \"Anyway, I believe the team, although bit delay and less communication at recent days, they really tried best for paper and cooperation\",\n",
    "]\n",
    "# simple context free grammar\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP | VP | Adv S | S Conj S \n",
    "    NP -> Det N | Det N PP | Det Adj N | Det Adj N PP | NP PP | Pronoun | NP Conj NP | Adj NP | N | Det PP | N NP | Det Adj | N Adv\n",
    "    PP -> P NP\n",
    "    VP -> V NP | VP PP | V | Adv VP | VP Adv | V Pronoun | V VP | V S\n",
    "    Det -> 'the' | 'a' | 'your' | 'our' | 'his' | 'all' | 'which' | 'some' | 'their'\n",
    "    Adj -> 'next' | 'recent' | 'bit' | 'less' \n",
    "    Adv -> 'anyway' | 'really'  | 'even' | 'lately'  \n",
    "    Pronoun -> 'us' | 'they' | 'i' | 'you' | 'he' | 'she' | 'who' | 'it' | 'them' | 'there'\n",
    "    N -> 'doctor' | 'team' | 'message' | 'words' | 'contract' | 'days' | 'paper' | 'cooperation' | 'delay' | 'communication' | 'thoughts' | 'checking' | 'best' | 'delays'\n",
    "    P -> 'to' | 'as' | 'for' | 'of' | 'at' | 'with' | 'in' | 'on' | 'by'\n",
    "    V -> 'show' | 'believe' | 'tried' | 'thank' | 'helped' | 'assist' | 'convey' | 'will' | 'were' | 'did'\n",
    "    Conj -> 'and' | 'though' | 'although'\n",
    "\"\"\")\n",
    "stop_words = [ '.', ',']\n",
    "# create a parser\n",
    "parser = nltk.ChartParser(grammar)\n",
    "# parse the sentences\n",
    "# fix the sentences\n",
    "# to make them more grammatically correct\n",
    "# and to match the grammar\n",
    "def sentence_fixer(sentence):\n",
    "    replace = {\n",
    "        \"your message\": \"you for your message,\",\n",
    "        \"to show our words\": \"it helped convey our thoughts\",\n",
    "        \"as his\": \"who will assist all of us with checking the\",\n",
    "        \"checking, to all of us\": \".\",\n",
    "        \"anyway, \": \"\",\n",
    "        \", although\": \" really did their best with the paper,\",\n",
    "        \"bit delay\": \"though there were some delays\",\n",
    "        \"at recent days,\": \"lately.\",\n",
    "        \"they really tried best for paper and cooperation\": \"\"\n",
    "    }\n",
    "    for key, value in replace.items():\n",
    "        sentence = sentence.lower().replace(key, value)\n",
    "    return sentence\n",
    "\n",
    "sentences_fixed = [sentence_fixer(sentence) for sentence in sentences]\n",
    "\n",
    "for sentence in sentences_fixed:\n",
    "    print(f\"Parsing: {sentence}\")\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    tokens = [token.lower() for token in tokens if token not in stop_words]\n",
    "    print(f\"Tokens: {tokens}\")\n",
    "    \n",
    "    try:\n",
    "        tree = next(parser.parse(tokens))\n",
    "        print(tree)\n",
    "        tree.pretty_print()\n",
    "    except StopIteration:\n",
    "        print(\"No parse tree found.\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "377f6326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in our lives.\n",
      "Paraphrased: Our Chinese culture celebrates today's dragon boat festival to ensure the safety and prosperity of all who come from this world.\n",
      "Paraphrased: In our Chinese culture, we celebrate today's dragon boat festival to make it a day to remember with great safety and comfort.\n",
      "Paraphrased: According to Chinese customs, today's celebration of the dragon boat is a way to honor the safety and greatness of our lives.\n",
      "\n",
      "\n",
      "Original: Hope you too, to enjoy it as my deepest wishes.\n",
      "Paraphrased: Let's all have a wonderful time together, dear friends.\n",
      "Paraphrased: May you also have a good time as my thoughts are with you.\n",
      "Paraphrased: I hope you enjoy it as much as I do.\n",
      "\n",
      "\n",
      "Original: Thank your message to show our words to the doctor, as his next contract checking, to all of us.\n",
      "Paraphrased: As the doctor conducts his next contract check, I thank you for your message on how we can communicate with him.\n",
      "Paraphrased: We appreciate your message, as we are tasked with sharing our thoughts with the doctor during his next contract check-up.\n",
      "Paraphrased: I want to thank you for your message, as we are preparing to discuss with the doctor during his next contract check.\n",
      "\n",
      "\n",
      "Original: I got this message to see the approved message.\n",
      "Paraphrased: I was notified to view the authorized message.\n",
      "Paraphrased: The message was sent to me with the intention of viewing the authorized message.\n",
      "Paraphrased: My intention is to view the authorized message after receiving this message.\n",
      "\n",
      "\n",
      "Original: In fact, I have received the message from the professor, to show me, this, a couple of days ago.\n",
      "Paraphrased: It's been two days since the professor sent me a message, so I had to show him this.\n",
      "Paraphrased: A message was sent by the professor to me, showing me this a few days ago.\n",
      "Paraphrased: The professor sent me a message to show me this, which happened just 1-2 days ago.\n",
      "\n",
      "\n",
      "Original: I am very appreciated the full support of the professor, for our Springer proceedings publication\n",
      "Paraphrased: The professor's complete backing has been appreciated for publishing our Springer proceedings.\n",
      "Paraphrased: It is truly appreciated to have the complete support of the professor in assisting us with our Springer proceedings publication.\n",
      "Paraphrased: Thanks to the professor's complete support, I am able to publish our Springer proceedings.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\").to(device)\n",
    "\n",
    "def paraphrase(\n",
    "    question,\n",
    "    num_beams=5,\n",
    "    num_beam_groups=5,\n",
    "    num_return_sequences=3,\n",
    "    repetition_penalty=10.0,\n",
    "    diversity_penalty=3.0,\n",
    "    no_repeat_ngram_size=2,\n",
    "    temperature=0.7,\n",
    "    max_length=128\n",
    "):\n",
    "    input_ids = tokenizer(\n",
    "        f'paraphrase: {question}',\n",
    "        return_tensors=\"pt\", padding=\"longest\",\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "    ).input_ids.to(device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids, temperature=temperature, repetition_penalty=repetition_penalty,\n",
    "        num_return_sequences=num_return_sequences, no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "        num_beams=num_beams, num_beam_groups=num_beam_groups,\n",
    "        max_length=max_length, diversity_penalty=diversity_penalty\n",
    "    )\n",
    "\n",
    "    res = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    return res\n",
    "\n",
    "text1 = [\"Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in our lives.\",\n",
    "\"Hope you too, to enjoy it as my deepest wishes.\",\n",
    "\"Thank your message to show our words to the doctor, as his next contract checking, to all of us.\",\n",
    "\"I got this message to see the approved message.\",\n",
    "\"In fact, I have received the message from the professor, to show me, this, a couple of days ago.\",\n",
    "\"I am very appreciated the full support of the professor, for our Springer proceedings publication\"\n",
    "]\n",
    "\n",
    "for text in text1:\n",
    "    print(f\"Original: {text}\")\n",
    "    paraphrased = paraphrase(text)\n",
    "    for p in paraphrased:\n",
    "        print(f\"Paraphrased: {p}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e22c8aa",
   "metadata": {},
   "source": [
    "chatgpt_paraphraser:\n",
    "  author={Vladimir Vorobev, Maxim Kuznetsov},\n",
    "  title={A paraphrasing model based on ChatGPT paraphrases},\n",
    "  year={2023}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
