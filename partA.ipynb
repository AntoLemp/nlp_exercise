{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bba1b8c9",
   "metadata": {},
   "source": [
    "## PartA\n",
    "In the 1st part, we are going to choose one sentence from each of the following texts and reconstruct them in a way that make sense.\n",
    "\n",
    "In the 2nd part, we are going to choose 3 Paraphrasers from https://huggingface.co/ to paraphrase the text.\n",
    "\n",
    "Then we are going to save the new text into .txt files and a benchmark so we can compare them later\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a23412",
   "metadata": {},
   "source": [
    "Text1 =\n",
    "Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in\n",
    "our lives. Hope you too, to enjoy it as my deepest wishes.\n",
    "Thank your message to show our words to the doctor, as his next contract checking, to all of us.\n",
    "I got this message to see the approved message. In fact, I have received the message from the\n",
    "professor, to show me, this, a couple of days ago. I am very appreciated the full support of the\n",
    "professor, for our Springer proceedings publication\n",
    "\n",
    "Text2 = \n",
    "During our final discuss, I told him about the new submission — the one we were waiting since\n",
    "last autumn, but the updates was confusing as it not included the full feedback from reviewer or\n",
    "maybe editor?\n",
    "Anyway, I believe the team, although bit delay and less communication at recent days, they really\n",
    "tried best for paper and cooperation. We should be grateful, I mean all of us, for the acceptance\n",
    "and efforts until the Springer link came finally last week, I think.\n",
    "Also, kindly remind me please, if the doctor still plan for the acknowledgments section edit before\n",
    "he sending again. Because I didn’t see that part final yet, or maybe I missed, I apologize if so.\n",
    "Overall, let us make sure all are safe and celebrate the outcome with strong coffee and future\n",
    "targets\n",
    "\n",
    "From text1 we chose the sentence: Thank your message to show our words to the doctor, as his next contract checking, to all of us\n",
    "\n",
    "From text2 we chose the sentence: Anyway, I believe the team, although bit delay and less communication at recent days, they really\n",
    "tried best for paper and cooperation\n",
    "\n",
    "To make sure the sentences we reconstruct are grammatically correct we are going to create a simple grammar in which we are going to parse the reconstructed sentences to at least determine whether or not they are grammatically correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c820456c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing: thank you for your message,\n",
      "Tokens: ['thank', 'you', 'for', 'your', 'message']\n",
      "(S\n",
      "  (VP\n",
      "    (V thank)\n",
      "    (NP (NP (Pronoun you)) (PP (P for) (NP (Det your) (N message))))))\n",
      "               S                      \n",
      "               |                       \n",
      "               VP                     \n",
      "   ____________|___                    \n",
      "  |                NP                 \n",
      "  |       _________|___                \n",
      "  |      |             PP             \n",
      "  |      |      _______|____           \n",
      "  |      NP    |            NP        \n",
      "  |      |     |        ____|_____     \n",
      "  V   Pronoun  P      Det         N   \n",
      "  |      |     |       |          |    \n",
      "thank   you   for     your     message\n",
      "\n",
      "\n",
      "\n",
      "Parsing: it helped convey our thoughts to the doctor,\n",
      "Tokens: ['it', 'helped', 'convey', 'our', 'thoughts', 'to', 'the', 'doctor']\n",
      "(S\n",
      "  (NP (Pronoun it))\n",
      "  (VP\n",
      "    (VP (V helped) (VP (V convey) (NP (Det our) (N thoughts))))\n",
      "    (PP (P to) (NP (Det the) (N doctor)))))\n",
      "                           S                                 \n",
      "    _______________________|_________                         \n",
      "   |                                 VP                      \n",
      "   |                    _____________|__________              \n",
      "   |                   VP                       |            \n",
      "   |       ____________|___                     |             \n",
      "   |      |                VP                   PP           \n",
      "   |      |       _________|___              ___|___          \n",
      "   NP     |      |             NP           |       NP       \n",
      "   |      |      |          ___|_____       |    ___|____     \n",
      "Pronoun   V      V        Det        N      P  Det       N   \n",
      "   |      |      |         |         |      |   |        |    \n",
      "   it   helped convey     our     thoughts  to the     doctor\n",
      "\n",
      "\n",
      "\n",
      "Parsing: who will assist all of us with checking the next contract .\n",
      "Tokens: ['who', 'will', 'assist', 'all', 'of', 'us', 'with', 'checking', 'the', 'next', 'contract']\n",
      "(S\n",
      "  (NP (Pronoun who))\n",
      "  (VP\n",
      "    (VP\n",
      "      (V will)\n",
      "      (VP (V assist) (NP (Det all) (PP (P of) (NP (Pronoun us))))))\n",
      "    (PP\n",
      "      (P with)\n",
      "      (NP (N checking) (NP (Det the) (Adj next) (N contract))))))\n",
      "               S                                                               \n",
      "    ___________|_______________________                                         \n",
      "   |                                   VP                                      \n",
      "   |                  _________________|___________________                     \n",
      "   |                 VP                                    |                   \n",
      "   |      ___________|___                                  |                    \n",
      "   |     |               VP                                |                   \n",
      "   |     |      _________|___                              |                    \n",
      "   |     |     |             NP                            PP                  \n",
      "   |     |     |      _______|___             _____________|___                 \n",
      "   |     |     |     |           PP          |                 NP              \n",
      "   |     |     |     |        ___|_____      |       __________|___             \n",
      "   NP    |     |     |       |         NP    |      |              NP          \n",
      "   |     |     |     |       |         |     |      |       _______|______      \n",
      "Pronoun  V     V    Det      P      Pronoun  P      N     Det     Adj     N    \n",
      "   |     |     |     |       |         |     |      |      |       |      |     \n",
      "  who   will assist all      of        us   with checking the     next contract\n",
      "\n",
      "\n",
      "\n",
      "Parsing: i believe the team really did their best with the paper, though there were some delays and less communication lately. \n",
      "Tokens: ['i', 'believe', 'the', 'team', 'really', 'did', 'their', 'best', 'with', 'the', 'paper', 'though', 'there', 'were', 'some', 'delays', 'and', 'less', 'communication', 'lately']\n",
      "(S\n",
      "  (NP (Pronoun i))\n",
      "  (VP\n",
      "    (VP\n",
      "      (V believe)\n",
      "      (S\n",
      "        (NP (Det the) (N team))\n",
      "        (VP\n",
      "          (Adv really)\n",
      "          (VP\n",
      "            (V did)\n",
      "            (S\n",
      "              (NP\n",
      "                (NP\n",
      "                  (NP (Det their) (N best))\n",
      "                  (PP (P with) (NP (Det the) (N paper))))\n",
      "                (Conj though)\n",
      "                (NP (Pronoun there)))\n",
      "              (VP\n",
      "                (V were)\n",
      "                (NP\n",
      "                  (NP (Det some) (N delays))\n",
      "                  (Conj and)\n",
      "                  (NP (Adj less) (NP (N communication))))))))))\n",
      "    (Adv lately)))\n",
      "                                                             S                                                                                  \n",
      "    _________________________________________________________|________                                                                           \n",
      "   |                                                                  VP                                                                        \n",
      "   |              ____________________________________________________|_____________________________________________________________________     \n",
      "   |             VP                                                                                                                         |   \n",
      "   |        _____|_____________                                                                                                             |    \n",
      "   |       |                   S                                                                                                            |   \n",
      "   |       |          _________|___________________                                                                                         |    \n",
      "   |       |         |                             VP                                                                                       |   \n",
      "   |       |         |          ___________________|________________________                                                                |    \n",
      "   |       |         |         |                                            VP                                                              |   \n",
      "   |       |         |         |      ______________________________________|_______                                                        |    \n",
      "   |       |         |         |     |                                              S                                                       |   \n",
      "   |       |         |         |     |                        ______________________|____________________                                   |    \n",
      "   |       |         |         |     |                       NP                                          VP                                 |   \n",
      "   |       |         |         |     |                   ____|______________________       ______________|_____                             |    \n",
      "   |       |         |         |     |                  NP                  |       |     |                    NP                           |   \n",
      "   |       |         |         |     |          ________|____               |       |     |          __________|_________                   |    \n",
      "   |       |         |         |     |         |             PP             |       |     |         |          |         NP                 |   \n",
      "   |       |         |         |     |         |         ____|___           |       |     |         |          |     ____|________          |    \n",
      "   NP      |         NP        |     |         NP       |        NP         |       NP    |         NP         |    |             NP        |   \n",
      "   |       |      ___|___      |     |     ____|___     |     ___|____      |       |     |     ____|____      |    |             |         |    \n",
      "Pronoun    V    Det      N    Adv    V   Det       N    P   Det       N    Conj  Pronoun  V   Det        N    Conj Adj            N        Adv  \n",
      "   |       |     |       |     |     |    |        |    |    |        |     |       |     |    |         |     |    |             |         |    \n",
      "   i    believe the     team really did their     best with the     paper though  there  were some     delays and  less     communication lately\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# Load the sentences from the files\n",
    "with open(\"paraphrased_text/sentence1.txt\", \"r\") as f1, open(\"paraphrased_text/sentence2.txt\", \"r\") as f2:\n",
    "    sentence1 = f1.read().strip().split('\\n')\n",
    "    sentence2 = f2.read().strip().split('\\n')\n",
    "# Simple context free grammar\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP | VP | Adv S | S Conj S \n",
    "    NP -> Det N | Det N PP | Det Adj N | Det Adj N PP | NP PP | Pronoun | NP Conj NP | Adj NP | N | Det PP | N NP | Det Adj | N Adv\n",
    "    PP -> P NP\n",
    "    VP -> V NP | VP PP | V | Adv VP | VP Adv | V Pronoun | V VP | V S\n",
    "    Det -> 'the' | 'a' | 'your' | 'our' | 'his' | 'all' | 'which' | 'some' | 'their'\n",
    "    Adj -> 'next' | 'recent' | 'bit' | 'less' \n",
    "    Adv -> 'anyway' | 'really'  | 'even' | 'lately'  \n",
    "    Pronoun -> 'us' | 'they' | 'i' | 'you' | 'he' | 'she' | 'who' | 'it' | 'them' | 'there'\n",
    "    N -> 'doctor' | 'team' | 'message' | 'words' | 'contract' | 'days' | 'paper' | 'cooperation' | 'delay' | 'communication' | 'thoughts' | 'checking' | 'best' | 'delays'\n",
    "    P -> 'to' | 'as' | 'for' | 'of' | 'at' | 'with' | 'in' | 'on' | 'by'\n",
    "    V -> 'show' | 'believe' | 'tried' | 'thank' | 'helped' | 'assist' | 'convey' | 'will' | 'were' | 'did'\n",
    "    Conj -> 'and' | 'though' | 'although'\n",
    "\"\"\")\n",
    "stop_words = [ '.', ',']\n",
    "# Create a parser\n",
    "parser = nltk.ChartParser(grammar)\n",
    "# Parse the sentences.\n",
    "# Fix the sentences\n",
    "# to make them more grammatically correct\n",
    "# and to match the grammar\n",
    "def sentence_fixer(sentence):\n",
    "    replace = {\n",
    "        \"your message\": \"you for your message,\",\n",
    "        \"to show our words\": \"it helped convey our thoughts\",\n",
    "        \"as his\": \"who will assist all of us with checking the\",\n",
    "        \"checking, to all of us\": \".\",\n",
    "        \"anyway, \": \"\",\n",
    "        \", although\": \" really did their best with the paper,\",\n",
    "        \"bit delay\": \"though there were some delays\",\n",
    "        \"at recent days,\": \"lately.\",\n",
    "        \"they really tried best for paper and cooperation\": \"\"\n",
    "    }\n",
    "    for key, value in replace.items():\n",
    "        sentence = sentence.lower().replace(key, value)\n",
    "    return sentence\n",
    "# Save the fixed sentences to files\n",
    "sentences_fixed1 = [sentence_fixer(sentence) for sentence in sentence1]\n",
    "sentences_fixed2 = [sentence_fixer(sentence) for sentence in sentence2]\n",
    "with open(\"paraphrased_text/fixed_sentence1.txt\", \"w\") as f1, open(\"paraphrased_text/fixed_sentence2.txt\", \"w\") as f2:\n",
    "    f1.write(sentences_fixed1 if isinstance(sentences_fixed1, str) else \"\\n\".join(sentences_fixed1))\n",
    "    f2.write(sentences_fixed2 if isinstance(sentences_fixed2, str) else \"\\n\".join(sentences_fixed2))\n",
    "\n",
    "sentences_fixed = sentences_fixed1 + sentences_fixed2\n",
    "# Parse the sentences\n",
    "for sentence in sentences_fixed:\n",
    "    print(f\"Parsing: {sentence}\")\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    tokens = [token.lower() for token in tokens if token not in stop_words]\n",
    "    print(f\"Tokens: {tokens}\")\n",
    "    \n",
    "    try:\n",
    "        tree = next(parser.parse(tokens))\n",
    "        print(tree)\n",
    "        tree.pretty_print()\n",
    "    except StopIteration:\n",
    "        print(\"No parse tree found.\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4f2e817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT Paraphraser\n",
    "device = \"cpu\"\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\").to(device)\n",
    "def paraphrase(\n",
    "    question,\n",
    "    ParaphraseKeyword = False,\n",
    "    num_beams=5,\n",
    "    num_beam_groups=5,\n",
    "    num_return_sequences=1,\n",
    "    repetition_penalty=10.0,\n",
    "    diversity_penalty=3.0,\n",
    "    no_repeat_ngram_size=2,\n",
    "    temp=0.9,\n",
    "    max_length=128\n",
    "):\n",
    "    if ParaphraseKeyword:\n",
    "        input_text = f'Paraphrase: {question}'\n",
    "    else:\n",
    "        input_text = f'{question}'\n",
    "    input_ids = tokenizer(\n",
    "        input_text,\n",
    "        return_tensors=\"pt\", padding=\"longest\",\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "    ).input_ids.to(device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids, temperature=temp, repetition_penalty=repetition_penalty,\n",
    "        num_return_sequences=num_return_sequences, no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "        num_beams=num_beams, num_beam_groups=num_beam_groups,\n",
    "        max_length=max_length, diversity_penalty=diversity_penalty\n",
    "    )\n",
    "\n",
    "    res = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    return res\n",
    "\n",
    "# Load the text from the files\n",
    "with open(\"paraphrased_text/text1.txt\", \"r\") as f1, open(\"paraphrased_text/text2.txt\", \"r\") as f2:\n",
    "    text1 = f1.read().strip().split('\\n')\n",
    "    text2 = f2.read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "377f6326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in our lives.\n",
      "Paraphrased: Our Chinese culture features a dragon boat festival today, designed to celebrate with all that is good and safe in our lives.\n",
      "\n",
      "\n",
      "Original: Hope you too, to enjoy it as my deepest wishes.\n",
      "Paraphrased: May it be as my heartfelt thanks for the opportunity to have a wonderful time with you, too.\n",
      "\n",
      "\n",
      "Original: Thank your message to show our words to the doctor, as his next contract checking, to all of us.\n",
      "Paraphrased: Thank you for your message to show us what we said to the doctor as his next contract checking.\n",
      "\n",
      "\n",
      "Original: I got this message to see the approved message.\n",
      "Paraphrased: I received this message to view the authorized message.\n",
      "\n",
      "\n",
      "Original: In fact, I have received the message from the professor, to show me, this, a couple of days ago.\n",
      "Paraphrased: I received the message from the professor a few days ago, to show me this.\n",
      "\n",
      "\n",
      "Original: I am very appreciated the full support of the professor, for our Springer proceedings publication\n",
      "Paraphrased: The professor's complete backing for our Springer proceedings publication is greatly appreciated, especially since I am grateful for their unwavering support.\n",
      "\n",
      "\n",
      "Final Paraphrased Text1:\n",
      "Our Chinese culture features a dragon boat festival today, designed to celebrate with all that is good and safe in our lives.\n",
      "May it be as my heartfelt thanks for the opportunity to have a wonderful time with you, too.\n",
      "Thank you for your message to show us what we said to the doctor as his next contract checking.\n",
      "I received this message to view the authorized message.\n",
      "I received the message from the professor a few days ago, to show me this.\n",
      "The professor's complete backing for our Springer proceedings publication is greatly appreciated, especially since I am grateful for their unwavering support.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ChatGPT (T5) Paraphraser\n",
    "paraphrased_text1 = \"\"\n",
    "for text in text1:\n",
    "    print(f\"Original: {text}\")\n",
    "    paraphrased = paraphrase(text)\n",
    "    for p in paraphrased:\n",
    "        print(f\"Paraphrased: {p}\")\n",
    "        paraphrased_text1 += p + \"\\n\"\n",
    "        \n",
    "    print(\"\\n\")\n",
    "print(\"Final Paraphrased Text1:\")\n",
    "print(paraphrased_text1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8ad6f9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: “During our final discuss, I told him about the new submission — the one we were waiting since last autumn, but the updates was confusing as it not included the full feedback from reviewer or maybe editor?\n",
      "Paraphrased: During our last discussion, I shared with him the news of the new submission we had been waiting for last autumn, but the changes were not complete as they did not include full feedback from the reviewer or editor.\n",
      "\n",
      "\n",
      "Original: Anyway, I believe the team, although bit delay and less communication at recent days, they really tried best for paper and cooperation.\n",
      "Paraphrased: Despite experiencing some delays and less communication than in recent days, the team did well on paper and cooperated effectively.\n",
      "\n",
      "\n",
      "Original: We should be grateful, I mean all of us, for the acceptance and efforts until the Springer link came finally last week, I think.\n",
      "Paraphrased: The collective agreement and efforts made until the Springer link was finally announced last week are greatly appreciated, I think.\n",
      "\n",
      "\n",
      "Original: Also, kindly remind me please, if the doctor still plan for the acknowledgments section edit before he sending again.\n",
      "Paraphrased: In case the doctor decides to revise the acknowledgments section before resending, please keep this in mind.\n",
      "\n",
      "\n",
      "Original: Because I didn't see that part final yet, or maybe I missed, I apologize if so.\n",
      "Paraphrased: I didn't witness that final segment yet, or maybe I missed it altogether, but if so, I'm sorry.\n",
      "\n",
      "\n",
      "Original: Overall, let us make sure all are safe and celebrate the outcome with strong coffee and future targets”\n",
      "Paraphrased: Let us ensure the safety of all and celebrate the outcome with strong coffee and future targets.\n",
      "\n",
      "\n",
      "Final Paraphrased Text2:\n",
      "During our last discussion, I shared with him the news of the new submission we had been waiting for last autumn, but the changes were not complete as they did not include full feedback from the reviewer or editor.\n",
      "Despite experiencing some delays and less communication than in recent days, the team did well on paper and cooperated effectively.\n",
      "The collective agreement and efforts made until the Springer link was finally announced last week are greatly appreciated, I think.\n",
      "In case the doctor decides to revise the acknowledgments section before resending, please keep this in mind.\n",
      "I didn't witness that final segment yet, or maybe I missed it altogether, but if so, I'm sorry.\n",
      "Let us ensure the safety of all and celebrate the outcome with strong coffee and future targets.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ChatGPT (T5) Paraphraser\n",
    "paraphrased_text2 = \"\"\n",
    "for text in text2:\n",
    "    print(f\"Original: {text}\")\n",
    "    paraphrased = paraphrase(text)\n",
    "    for p in paraphrased:\n",
    "        print(f\"Paraphrased: {p}\")\n",
    "        paraphrased_text2 += p + \"\\n\"\n",
    "        \n",
    "    print(\"\\n\")\n",
    "print(\"Final Paraphrased Text2:\")\n",
    "print(paraphrased_text2)\n",
    "\n",
    "# Save the paraphrased texts to files\n",
    "with open(\"paraphrased_text/chatgpt_t5_paraphrased_text1.txt\", \"w\") as f1, open(\"paraphrased_text/chatgpt_t5_paraphrased_text2.txt\", \"w\") as f2:\n",
    "    f1.write(paraphrased_text1)\n",
    "    f2.write(paraphrased_text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e22c8aa",
   "metadata": {},
   "source": [
    "chatgpt_paraphraser:\n",
    "  author={Vladimir Vorobev, Maxim Kuznetsov},\n",
    "  title={A paraphrasing model based on ChatGPT paraphrases},\n",
    "  year={2023}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4f23a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at tuner007/pegasus_paraphrase and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in our lives.\n",
      "Paraphrased: Our Chinese culture has a dragon boat festival that is celebrated today.\n",
      "\n",
      "\n",
      "Original: Hope you too, to enjoy it as my deepest wishes.\n",
      "Paraphrased: Hope you enjoy it as I wish.\n",
      "\n",
      "\n",
      "Original: Thank your message to show our words to the doctor, as his next contract checking, to all of us.\n",
      "Paraphrased: Thank you for your message, which will be shown to the doctor.\n",
      "\n",
      "\n",
      "Original: I got this message to see the approved message.\n",
      "Paraphrased: I received this message to see the approved one.\n",
      "\n",
      "\n",
      "Original: In fact, I have received the message from the professor, to show me, this, a couple of days ago.\n",
      "Paraphrased: I received a message from the professor, to show me what he was talking about.\n",
      "\n",
      "\n",
      "Original: I am very appreciated the full support of the professor, for our Springer proceedings publication\n",
      "Paraphrased: The professor supported the Springer proceedings publication.\n",
      "\n",
      "\n",
      "Final Paraphrased Text1:\n",
      "Our Chinese culture has a dragon boat festival that is celebrated today.\n",
      "Hope you enjoy it as I wish.\n",
      "Thank you for your message, which will be shown to the doctor.\n",
      "I received this message to see the approved one.\n",
      "I received a message from the professor, to show me what he was talking about.\n",
      "The professor supported the Springer proceedings publication.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pegasus Paraphraser\n",
    "\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"tuner007/pegasus_paraphrase\")\n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"tuner007/pegasus_paraphrase\").to(device)\n",
    "paraphrased_text1 = \"\"\n",
    "for text in text1:\n",
    "    print(f\"Original: {text}\")\n",
    "    paraphrased = paraphrase(text)\n",
    "    for p in paraphrased:\n",
    "        print(f\"Paraphrased: {p}\")\n",
    "        paraphrased_text1 += p + \"\\n\"\n",
    "        \n",
    "    print(\"\\n\")\n",
    "print(\"Final Paraphrased Text1:\")\n",
    "print(paraphrased_text1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6e62f2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: “During our final discuss, I told him about the new submission — the one we were waiting since last autumn, but the updates was confusing as it not included the full feedback from reviewer or maybe editor?\n",
      "Paraphrased: During our final discussion, I told him about the new submission that we were waiting for but it wasn't included with the other updates.\n",
      "\n",
      "\n",
      "Original: Anyway, I believe the team, although bit delay and less communication at recent days, they really tried best for paper and cooperation.\n",
      "Paraphrased: The team tried their best for paper and cooperation despite the recent delay.\n",
      "\n",
      "\n",
      "Original: We should be grateful, I mean all of us, for the acceptance and efforts until the Springer link came finally last week, I think.\n",
      "Paraphrased: I think we should be grateful for the acceptance and efforts until last week, when the Springer link came.\n",
      "\n",
      "\n",
      "Original: Also, kindly remind me please, if the doctor still plan for the acknowledgments section edit before he sending again.\n",
      "Paraphrased: The doctor should plan for the acknowledgments section to be edited before he sends again.\n",
      "\n",
      "\n",
      "Original: Because I didn't see that part final yet, or maybe I missed, I apologize if so.\n",
      "Paraphrased: I apologize if I missed that part final.\n",
      "\n",
      "\n",
      "Original: Overall, let us make sure all are safe and celebrate the outcome with strong coffee and future targets”\n",
      "Paraphrased: Let us make sure all are safe and celebrate the outcome with coffee and targets.\n",
      "\n",
      "\n",
      "Final Paraphrased Text2:\n",
      "During our final discussion, I told him about the new submission that we were waiting for but it wasn't included with the other updates.\n",
      "The team tried their best for paper and cooperation despite the recent delay.\n",
      "I think we should be grateful for the acceptance and efforts until last week, when the Springer link came.\n",
      "The doctor should plan for the acknowledgments section to be edited before he sends again.\n",
      "I apologize if I missed that part final.\n",
      "Let us make sure all are safe and celebrate the outcome with coffee and targets.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pegasus Paraphraser\n",
    "paraphrased_text2 = \"\"\n",
    "for text in text2:\n",
    "    print(f\"Original: {text}\")\n",
    "    paraphrased = paraphrase(text)\n",
    "    for p in paraphrased:\n",
    "        print(f\"Paraphrased: {p}\")\n",
    "        paraphrased_text2 += p + \"\\n\"\n",
    "        \n",
    "    print(\"\\n\")\n",
    "print(\"Final Paraphrased Text2:\")\n",
    "print(paraphrased_text2)\n",
    "# Save the paraphrased texts to files\n",
    "with open(\"paraphrased_text/pegasus_paraphrased_text1.txt\", \"w\") as f1, open(\"paraphrased_text/pegasus_paraphrased_text2.txt\", \"w\") as f2:\n",
    "    f1.write(paraphrased_text1)\n",
    "    f2.write(paraphrased_text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e18a115",
   "metadata": {},
   "source": [
    "@misc{zhang2019pegasus,\n",
    "    title={PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization},\n",
    "    author={Jingqing Zhang and Yao Zhao and Mohammad Saleh and Peter J. Liu},\n",
    "    year={2019},\n",
    "    eprint={1912.08777},\n",
    "    archivePrefix={arXiv},\n",
    "    primaryClass={cs.CL}\n",
    "}\n",
    "\n",
    "Created by Arpit Rajauria https://x.com/arpit_rajauria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c6e666b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in our lives.\n",
      "Paraphrased:  Today is the Dragon Boat Festival, and in Chinese culture we celebrate it with everything safe and beautiful in our lives.\n",
      "\n",
      "\n",
      "Original: Hope you too, to enjoy it as my deepest wishes.\n",
      "Paraphrased:  I hope you enjoy it as much as I do, my deepest wish.\n",
      "\n",
      "\n",
      "Original: Thank your message to show our words to the doctor, as his next contract checking, to all of us.\n",
      "Paraphrased:  I thank you for your report showing our words to the doctor, as well as his next contractual check-up on all of us.\n",
      "\n",
      "\n",
      "Original: I got this message to see the approved message.\n",
      "Paraphrased:  I received this message so I could see the approved report.\n",
      "\n",
      "\n",
      "Original: In fact, I have received the message from the professor, to show me, this, a couple of days ago.\n",
      "Paraphrased:  Actually, I got a message from the professor to show me this some time ago.\n",
      "\n",
      "\n",
      "Original: I am very appreciated the full support of the professor, for our Springer proceedings publication\n",
      "Paraphrased:  I appreciate the professor's full support for our Springer publication.\n",
      "\n",
      "\n",
      "Final Paraphrased Text1:\n",
      " Today is the Dragon Boat Festival, and in Chinese culture we celebrate it with everything safe and beautiful in our lives.\n",
      " I hope you enjoy it as much as I do, my deepest wish.\n",
      " I thank you for your report showing our words to the doctor, as well as his next contractual check-up on all of us.\n",
      " I received this message so I could see the approved report.\n",
      " Actually, I got a message from the professor to show me this some time ago.\n",
      " I appreciate the professor's full support for our Springer publication.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bart Paraphraser\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained('stanford-oval/paraphraser-bart-large')\n",
    "model = BartForConditionalGeneration.from_pretrained('stanford-oval/paraphraser-bart-large').to(device)\n",
    "paraphrased_text1 = \"\"\n",
    "for text in text1:\n",
    "    print(f\"Original: {text}\")\n",
    "    paraphrased = paraphrase(text)\n",
    "    for p in paraphrased:\n",
    "        print(f\"Paraphrased: {p}\")\n",
    "        paraphrased_text1 += p + \"\\n\"\n",
    "        \n",
    "    print(\"\\n\")\n",
    "print(\"Final Paraphrased Text1:\")\n",
    "print(paraphrased_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0f4ee556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: “During our final discuss, I told him about the new submission — the one we were waiting since last autumn, but the updates was confusing as it not included the full feedback from reviewer or maybe editor?\n",
      "Paraphrased:  During our last discussion, I told him about the new submission we had been waiting for since last fall, but that update was confusing because it didn't include any full feedback from a reviewer or even an editor?\n",
      "\n",
      "\n",
      "Original: Anyway, I believe the team, although bit delay and less communication at recent days, they really tried best for paper and cooperation.\n",
      "Paraphrased:  Anyway, I believe that the team, even if a little late and less communicative in recent days, has really tried their best to be paper-friendly and cooperative.\n",
      "\n",
      "\n",
      "Original: We should be grateful, I mean all of us, for the acceptance and efforts until the Springer link came finally last week, I think.\n",
      "Paraphrased:  I think we should all be grateful for his acceptance and effort until the Springer connection finally came last week.\n",
      "\n",
      "\n",
      "Original: Also, kindly remind me please, if the doctor still plan for the acknowledgments section edit before he sending again.\n",
      "Paraphrased:  Also, please remind me if the doctor is still planning to edit the acknowledgements section before sending it again.\n",
      "\n",
      "\n",
      "Original: Because I didn't see that part final yet, or maybe I missed, I apologize if so.\n",
      "Paraphrased:  Since I haven't seen the final part yet, or perhaps missed it, if you have, I apologize.\n",
      "\n",
      "\n",
      "Original: Overall, let us make sure all are safe and celebrate the outcome with strong coffee and future targets”\n",
      "Paraphrased:  All in all, let's make sure everyone is safe and celebrate the outcome with a strong cup of coffee and future goals.\n",
      "\n",
      "\n",
      "Final Paraphrased Text2:\n",
      " During our last discussion, I told him about the new submission we had been waiting for since last fall, but that update was confusing because it didn't include any full feedback from a reviewer or even an editor?\n",
      " Anyway, I believe that the team, even if a little late and less communicative in recent days, has really tried their best to be paper-friendly and cooperative.\n",
      " I think we should all be grateful for his acceptance and effort until the Springer connection finally came last week.\n",
      " Also, please remind me if the doctor is still planning to edit the acknowledgements section before sending it again.\n",
      " Since I haven't seen the final part yet, or perhaps missed it, if you have, I apologize.\n",
      " All in all, let's make sure everyone is safe and celebrate the outcome with a strong cup of coffee and future goals.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bart Paraphraser\n",
    "paraphrased_text2 = \"\"\n",
    "for text in text2:\n",
    "    print(f\"Original: {text}\")\n",
    "    paraphrased = paraphrase(text)\n",
    "    for p in paraphrased:\n",
    "        print(f\"Paraphrased: {p}\")\n",
    "        paraphrased_text2 += p + \"\\n\"\n",
    "        \n",
    "    print(\"\\n\")\n",
    "print(\"Final Paraphrased Text2:\")\n",
    "print(paraphrased_text2)\n",
    "\n",
    "# Save the paraphrased texts to files\n",
    "with open(\"paraphrased_text/bart_paraphrased_text1.txt\", \"w\") as f1, open(\"paraphrased_text/bart_paraphrased_text2.txt\", \"w\") as f2:\n",
    "    f1.write(paraphrased_text1)\n",
    "    f2.write(paraphrased_text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369dae2c",
   "metadata": {},
   "source": [
    "@inproceedings{xu-etal-2020-autoqa,\n",
    "    title = \"{A}uto{QA}: From Databases to {QA} Semantic Parsers with Only Synthetic Training Data\",\n",
    "    author = \"Xu, Silei  and Semnani, Sina  and Campagna, Giovanni  and Lam, Monica\",\n",
    "    booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n",
    "    month = nov,\n",
    "    year = \"2020\",\n",
    "    address = \"Online\",\n",
    "    publisher = \"Association for Computational Linguistics\",\n",
    "    url = \"https://www.aclweb.org/anthology/2020.emnlp-main.31\",\n",
    "    pages = \"422--434\",\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b1306b",
   "metadata": {},
   "source": [
    "## Using ChatGPT \n",
    "(https://chatgpt.com/share/68552e36-7b78-800f-8cb9-28b4dd15d294)\n",
    "\n",
    "We paraphrased the 2 text and saved them as benchmark_chatgpt_text1.txt and benchmark_chatgpt_text2.txt\n",
    "\n",
    "We will use them as a benchmark to compare the generated/reconstructed paraphrased texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7351c7",
   "metadata": {},
   "source": [
    "To evaluate the semantic consistency and transformation quality of the paraphrased texts, we used cosine similarity via TF-IDF vectorization. This method captures how closely the paraphrased versions align with the benchmark and original texts in terms of word usage and structure.\n",
    "\n",
    "We compared each paraphrased text against the benchmark reconstruction.\n",
    "\n",
    "The closer the cosine similarity is to 1.0 the better semantically aligned the texts are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73da4e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between Benchmark and Original Text1 : 0.6790\n",
      "Cosine Similarity between Benchmark and Original Text2 : 0.7174\n",
      "Cosine Similarity between Benchmark Sentence1 and Original Sentence1 : 0.4202\n",
      "Cosine Similarity between Benchmark Sentence2 and Original Sentence2 : 0.3301\n",
      "Cosine Similarity between ChatGPT T5 and Benchmark Text1 : 0.6003\n",
      "Cosine Similarity between ChatGPT T5 and Benchmark Text2 : 0.7301\n",
      "Cosine Similarity between Pegasus and Benchmark Text1 : 0.5105\n",
      "Cosine Similarity between Pegasus and Benchmark Text2 : 0.6726\n",
      "Cosine Similarity between BART and Benchmark Text1 : 0.6018\n",
      "Cosine Similarity between BART and Benchmark Text2 : 0.6827\n",
      "Cosine Similarity between Fixed Sentence1 and Benchmark Sentence1 : 0.5103\n",
      "Cosine Similarity between Fixed Sentence2 and Benchmark Sentence2 : 0.5920\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#Load original texts\n",
    "with open(\"paraphrased_text/text1.txt\", \"r\") as f1, open(\"paraphrased_text/text2.txt\", \"r\") as f2:\n",
    "    original_text1 = f1.read().strip()\n",
    "    original_text2 = f2.read().strip()\n",
    "# Load benchmark texts\n",
    "with open(\"paraphrased_text/benchmark_chatgpt_text1.txt\", \"r\") as f1, open(\"paraphrased_text/benchmark_chatgpt_text2.txt\", \"r\") as f2:\n",
    "    benchmark_text1 = f1.read().strip()\n",
    "    benchmark_text2 = f2.read().strip()\n",
    "# Load ChatGPT T5 paraphrased texts\n",
    "with open(\"paraphrased_text/chatgpt_t5_paraphrased_text1.txt\", \"r\") as f1, open(\"paraphrased_text/chatgpt_t5_paraphrased_text2.txt\", \"r\") as f2:\n",
    "    chatgpt_t5_text1 = f1.read().strip()\n",
    "    chatgpt_t5_text2 = f2.read().strip()\n",
    "# Load Pegasus paraphrased texts\n",
    "with open(\"paraphrased_text/pegasus_paraphrased_text1.txt\", \"r\") as f1, open(\"paraphrased_text/pegasus_paraphrased_text2.txt\", \"r\") as f2:\n",
    "    pegasus_text1 = f1.read().strip()\n",
    "    pegasus_text2 = f2.read().strip()\n",
    "# Load BART paraphrased texts\n",
    "with open(\"paraphrased_text/bart_paraphrased_text1.txt\", \"r\") as f1, open(\"paraphrased_text/bart_paraphrased_text2.txt\", \"r\") as f2:\n",
    "    bart_text1 = f1.read().strip()\n",
    "    bart_text2 = f2.read().strip()\n",
    "# Load fixed sentences\n",
    "with open(\"paraphrased_text/fixed_sentence1.txt\", \"r\") as f1, open(\"paraphrased_text/fixed_sentence2.txt\", \"r\") as f2:\n",
    "    fixed_sentence1 = f1.read().strip()\n",
    "    fixed_sentence2 = f2.read().strip()\n",
    "\n",
    "# Comput cosine similarity\n",
    "def compute_cosine_similarity(text1, text2):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([text1, text2])\n",
    "    return cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
    "\n",
    "for text1, text2, label in [\n",
    "    (original_text1, benchmark_text1, \"Benchmark and Original Text1\"),\n",
    "    (original_text2, benchmark_text2, \"Benchmark and Original Text2\"),\n",
    "    (original_text1.splitlines()[2], benchmark_text1.splitlines()[2], \"Benchmark Sentence1 and Original Sentence1\"),\n",
    "    (original_text2.splitlines()[1], benchmark_text2.splitlines()[1], \"Benchmark Sentence2 and Original Sentence2\"),\n",
    "    (benchmark_text1, chatgpt_t5_text1, \"ChatGPT T5 and Benchmark Text1\"),\n",
    "    (benchmark_text2, chatgpt_t5_text2, \"ChatGPT T5 and Benchmark Text2\"),\n",
    "    (benchmark_text1, pegasus_text1, \"Pegasus and Benchmark Text1\"),\n",
    "    (benchmark_text2, pegasus_text2, \"Pegasus and Benchmark Text2\"),\n",
    "    (benchmark_text1, bart_text1, \"BART and Benchmark Text1\"),\n",
    "    (benchmark_text2, bart_text2, \"BART and Benchmark Text2\"),\n",
    "    (benchmark_text1.splitlines()[2], fixed_sentence1, \"Fixed Sentence1 and Benchmark Sentence1\"),\n",
    "    (benchmark_text2.splitlines()[1], fixed_sentence2, \"Fixed Sentence2 and Benchmark Sentence2\"),\n",
    "]:\n",
    "    similarity = compute_cosine_similarity(text1, text2)\n",
    "    print(f\"Cosine Similarity between {label} : {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa817dfa",
   "metadata": {},
   "source": [
    "We will be discussing the results further in the report, but as we can see the similarity between the original texts and the benchmarks is around 0.7 meaning that even though we reconstructed it to make it more understandable, it kept its general meaning.\n",
    "\n",
    "We can also see that the reconstructed Text2 is way closer to Benchmark Text2, than the reconstructed Text1 to Benchmark Text1.\n",
    "Which makes sense, since the original Text1 didn't make as much sense as the original Text2 making the reconstruction even harder.\n",
    "\n",
    "Another thing we can see is that the reconstructed sentences we made, compared with the benchmark sentences, aren't that similar (only around 0.5-0.59 max). This is quite low which again indicated that the original sentences were grammaticaly/semantically ambiguous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656bd025",
   "metadata": {},
   "source": [
    "## First Conclusion\n",
    "\n",
    "Overall, we can see that all three models tried in a way to paraphrase as best as they could, although the meaning is still not 100% clear, it is way better than the original one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
